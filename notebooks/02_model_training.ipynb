{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26d1db08-1b7a-429f-8866-97ede53e0c75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Notebook: 02_model_training.py\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# 1. Definição da Tabela Bronze\n",
    "BRONZE_TABLE = \"dev_catalogue.staging_schema.bronze_insurance_costs\"\n",
    "SILVER_TABLE = \"dev_catalogue.staging_schema.silver_insurance_features\"\n",
    "\n",
    "# Leitura da Tabela Delta\n",
    "df_bronze = spark.read.table(BRONZE_TABLE)\n",
    "\n",
    "print(f\"DataFrame lido com sucesso da tabela Delta: {BRONZE_TABLE}\")\n",
    "df_bronze.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df7457fd-aea9-4b08-b161-f670785e785b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Colunas Categóricas (features que precisam de encoding)\n",
    "categorical_cols = [\"sex\", \"smoker\", \"region\"]\n",
    "\n",
    "# Cria StringIndexers para as colunas categóricas\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"keep\")\n",
    "    for col in categorical_cols\n",
    "]\n",
    "\n",
    "# Cria OneHotEncoders para as colunas indexadas\n",
    "encoders = [\n",
    "    OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_encoded\", handleInvalid=\"keep\")\n",
    "    for col in categorical_cols\n",
    "]\n",
    "\n",
    "# Colunas Numéricas Originais (já prontas)\n",
    "numerical_cols = [\"age\", \"bmi\", \"children\"]\n",
    "\n",
    "# Colunas Finais Codificadas (as numéricas originais + as categóricas codificadas)\n",
    "final_feature_cols = numerical_cols + [col + \"_encoded\" for col in categorical_cols]\n",
    "\n",
    "# Cria o VectorAssembler para combinar todas as features em uma única coluna\n",
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=final_feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# 3. Criação da Pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [vector_assembler])\n",
    "\n",
    "# Aplica a Pipeline no DataFrame\n",
    "pipeline_model = pipeline.fit(df_bronze)\n",
    "df_silver = pipeline_model.transform(df_bronze)\n",
    "\n",
    "# Seleciona as colunas necessárias para o treinamento (features e charges)\n",
    "df_silver = df_silver.select(\n",
    "    F.col(\"charges\").alias(\"label\"), # Renomeia a variável alvo para 'label' (padrão do Spark ML)\n",
    "    \"features\"\n",
    ")\n",
    "\n",
    "print(\"\\nDataFrame SILVER (Pré-Processado) pronto:\")\n",
    "df_silver.show(5, truncate=False)\n",
    "\n",
    "# 4. Salvar a Camada SILVER\n",
    "df_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(SILVER_TABLE)\n",
    "\n",
    "print(f\"\\n✅ Camada SILVER salva com sucesso na Tabela Delta: {SILVER_TABLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "057440f7-aecb-4324-9b03-f2f6f0d76278",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# 1. Divisão dos Dados (Treino e Teste)\n",
    "# Usaremos 80% para treino e 20% para teste\n",
    "(train_df, test_df) = df_silver.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"\\nDados de Treino: {train_df.count()} linhas\")\n",
    "print(f\"Dados de Teste: {test_df.count()} linhas\")\n",
    "\n",
    "# 2. Treinamento do Modelo de Regressão Linear\n",
    "lr = LinearRegression(featuresCol='features', labelCol='label', maxIter=10)\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "print(\"\\nModelo de Regressão Linear treinado com sucesso.\")\n",
    "\n",
    "# 3. Avaliação no Conjunto de Teste\n",
    "predictions_df = lr_model.transform(test_df)\n",
    "\n",
    "# Avalia o modelo usando Root Mean Squared Error (RMSE)\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions_df)\n",
    "r2 = evaluator.evaluate(predictions_df, {evaluator.metricName: \"r2\"})\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Resultado da Avaliação do Modelo:\")\n",
    "print(f\"  - RMSE (Root Mean Squared Error): {rmse:.2f}\")\n",
    "print(f\"  - R2 (Coeficiente de Determinação): {r2:.4f}\")\n",
    "print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_model_training",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
